{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ac554",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/facebookresearch/sam3.git\n",
    "cd sam3\n",
    "pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running example notebooks\n",
    "pip install -e \".[notebooks]\"\n",
    "\n",
    "# For development\n",
    "pip install -e \".[train,dev]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "login(token=token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f80dc5",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23211d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from sam3.model_builder import build_sam3_image_model\n",
    "from sam3.model.sam3_image_processor import Sam3Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94163b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://1.bp.blogspot.com/-1OiYytlrNoc/VQ6m0zn00CI/AAAAAAAAi_M/2Nc_D36ztVs/s1600/image028.jpg\"\n",
    "response = requests.get(URL)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_sam3_image_model()\n",
    "processor = Sam3Processor(model)\n",
    "inference_state = processor.set_image(image)\n",
    "output = processor.set_text_prompt(state=inference_state, prompt=\"<YOUR_TEXT_PROMPT>\")\n",
    "masks, boxes, scores = output[\"masks\"], output[\"boxes\"], output[\"scores\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d9fd3e",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Sam3VideoModel, Sam3VideoProcessor\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "\n",
    "device = Accelerator().device\n",
    "model = Sam3VideoModel.from_pretrained(\"facebook/sam3\").to(device, dtype=torch.bfloat16)\n",
    "processor = Sam3VideoProcessor.from_pretrained(\"facebook/sam3\")\n",
    "\n",
    "# Load video frames\n",
    "from transformers.video_utils import load_video\n",
    "video_url = \"https://huggingface.co/datasets/hf-internal-testing/sam2-fixtures/resolve/main/bedroom.mp4\"\n",
    "video_frames, _ = load_video(video_url)\n",
    "\n",
    "# Initialize video inference session\n",
    "inference_session = processor.init_video_session(\n",
    "    video=video_frames,\n",
    "    inference_device=device,\n",
    "    processing_device=\"cpu\",\n",
    "    video_storage_device=\"cpu\",\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Add text prompt to detect and track objects\n",
    "text = \"person\"\n",
    "inference_session = processor.add_text_prompt(\n",
    "    inference_session=inference_session,\n",
    "    text=text,\n",
    ")\n",
    "\n",
    "# Process all frames in the video\n",
    "outputs_per_frame = {}\n",
    "for model_outputs in model.propagate_in_video_iterator(\n",
    "    inference_session=inference_session, max_frame_num_to_track=50\n",
    "):\n",
    "    processed_outputs = processor.postprocess_outputs(inference_session, model_outputs)\n",
    "    outputs_per_frame[model_outputs.frame_idx] = processed_outputs\n",
    "\n",
    "print(f\"Processed {len(outputs_per_frame)} frames\")\n",
    "\n",
    "# Access results for a specific frame\n",
    "frame_0_outputs = outputs_per_frame[0]\n",
    "print(f\"Detected {len(frame_0_outputs['object_ids'])} objects\")\n",
    "print(f\"Object IDs: {frame_0_outputs['object_ids'].tolist()}\")\n",
    "print(f\"Scores: {frame_0_outputs['scores'].tolist()}\")\n",
    "print(f\"Boxes shape (XYXY format, absolute coordinates): {frame_0_outputs['boxes'].shape}\")\n",
    "print(f\"Masks shape: {frame_0_outputs['masks'].shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-sam3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
