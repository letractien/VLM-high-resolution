{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c1e776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/.venv-molmo/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "login(token=token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e69962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:43<00:00,  6.19s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "CACHE_DIR = \"./cache\"\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto',\n",
    "    cache_dir=CACHE_DIR,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto',\n",
    "    cache_dir=CACHE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b72a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This image captures a young black Labrador puppy, likely around six months old, sitting on a weathered wooden deck. The puppy's sleek, short fur is entirely black, including its nose, eyes, and ears, which are slightly floppy. The dog is positioned in the center of the frame, looking up directly at the camera with a curious and attentive expression. Its front paws are visible, with one slightly tucked under its body, while its back paws are hidden from view. The wooden deck beneath the puppy is made of light brown planks with visible knots and signs of wear, adding a rustic charm to the scene. The overall composition is simple yet striking, with the puppy's glossy black coat contrasting beautifully against the light wooden background.\n"
     ]
    }
   ],
   "source": [
    "# process the image and text\n",
    "inputs = processor.process(\n",
    "    images=[Image.open(requests.get(\"https://picsum.photos/id/237/536/354\", stream=True).raw)],\n",
    "    text=\"Describe this image.\"\n",
    ")\n",
    "\n",
    "# move inputs to the correct device and make a batch of size 1\n",
    "inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "\n",
    "# generate output; maximum 200 new tokens; stop generation when <|endoftext|> is generated\n",
    "output = model.generate_from_batch(\n",
    "    inputs,\n",
    "    GenerationConfig(max_new_tokens=200, stop_strings=\"<|endoftext|>\"),\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "\n",
    "# only get generated tokens; decode them to text\n",
    "generated_tokens = output[0,inputs['input_ids'].size(1):]\n",
    "generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "# print the generated text\n",
    "print(generated_text)\n",
    "# >>>  This image features an adorable black Labrador puppy, captured from a top-down\n",
    "#      perspective. The puppy is sitting on a wooden deck, which is composed ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-molmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
